{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Normalization\n",
    "\n",
    "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is *normalized* in order to work correctly. The idea of normalization, also known as *feature scaling*, is to ensure that all the data is on a similar scale, *i.e.* that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1.\n",
    "\n",
    "In this lab, you will be performing a different kind of feature scaling known as *mean normalization*. Mean normalization will scale the data, but instead of making the values be between 0 and 1, it will distribute the values evenly in some small interval around zero. For example, if we have a dataset that has values between 0 and 5,000, after mean normalization the range of values will be distributed in some small range around 0, for example between -3 to 3. Because the range of values are distributed evenly around zero, this guarantees that the average (mean) of all elements will be zero. Therefore, when you perform *mean normalization* your data will not only be scaled but it will also have an average of zero. \n",
    "\n",
    "# To Do:\n",
    "\n",
    "You will start by importing NumPy and creating a rank 2 ndarray of random integers between 0 and 5,000 (inclusive) with 1000 rows and 20 columns. This array will simulate a dataset with a wide range of values. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2153 4514 1679 ..., 1333 2961 4452]\n",
      " [3374 2941 3996 ..., 2445 4750  878]\n",
      " [4536 3931 1556 ..., 3571 4487 4363]\n",
      " ..., \n",
      " [ 768 2239 2346 ...,  874 2797 1760]\n",
      " [3293 4908 2578 ..., 2237 2383 1898]\n",
      " [2208  626  860 ..., 4995 1927 2177]]\n"
     ]
    }
   ],
   "source": [
    "# import NumPy into Python\n",
    "import numpy as np\n",
    "\n",
    "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
    "X = np.random.randint(1, 5001, size=(1000, 20))\n",
    "\n",
    "# print the shape of X\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you created the array we will mean normalize it. We will perform mean normalization using the following equation:\n",
    "\n",
    "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. In the space below, you will first calculate the average and standard deviation of each column of $X$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average of the values in each column of X\n",
    "ave_cols = np.mean(X, axis=0)\n",
    "\n",
    "# Standard Deviation of the values in each column of X\n",
    "std_cols = np.std(X, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have done the above calculations correctly, then `ave_cols` and `std_cols`, should both be vectors with shape `(20,)` since $X$ has 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of ave_cols\n",
    "print(ave_cols.shape)\n",
    "\n",
    "# Print the shape of std_cols\n",
    "print(std_cols.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now take advantage of Broadcasting to calculate the mean normalized version of $X$ in just one line of code using the equation above. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.24848787  1.40487111 -0.52289165 ..., -0.83088428  0.31027801\n",
      "   1.35313611]\n",
      " [ 0.5974041   0.31840021  1.08723521 ..., -0.05991641  1.54469702\n",
      "  -1.06801114]\n",
      " [ 1.40242167  1.00219309 -0.60836667 ...,  0.7207579   1.36322569\n",
      "   1.29284453]\n",
      " ..., \n",
      " [-1.20799677 -0.1664711  -0.05938081 ..., -1.14911653  0.19711719\n",
      "  -0.47051481]\n",
      " [ 0.54128841  1.67700686  0.10184035 ..., -0.20412623 -0.0885449\n",
      "  -0.37702899]\n",
      " [-0.21038462 -1.28057    -1.09203015 ...,  1.70804051 -0.40318719\n",
      "  -0.18802505]]\n"
     ]
    }
   ],
   "source": [
    "# Mean normalize X\n",
    "X_norm = (X[:] - ave_cols)/std_cols\n",
    "print(X_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have performed the mean normalization correctly, then the average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero, and they should be evenly distributed in some small interval around zero. You can verify this by filing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.42836870004e-17\n",
      "-1.72345041237\n",
      "1.72448053262\n"
     ]
    }
   ],
   "source": [
    "# Print the average of all the values of X_norm\n",
    "print(X_norm.mean())\n",
    "\n",
    "# Print the average of the minimum value in each column of X_norm\n",
    "print(np.min(X_norm[:], axis=0).mean())\n",
    "\n",
    "# Print the average of the maximum value in each column of X_norm\n",
    "print(np.max(X_norm[:], axis=0).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should note that since $X$ was created using random integers, the above values will vary. \n",
    "\n",
    "# Data Separation\n",
    "\n",
    "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
    "\n",
    "1. A Training Set\n",
    "2. A Cross Validation Set\n",
    "3. A Test Set\n",
    "\n",
    "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. \n",
    "\n",
    "In this part of the lab you will separate `X_norm` into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of `X_norm` chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of `X_norm` are chosen and randomly distributed among the three new sets.\n",
    "\n",
    "You will start by creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this by using the `np.random.permutation()` function. The `np.random.permutation(N)` function creates a random permutation of integers from 0 to `N - 1`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 2, 0, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a random permutation of integers 0 to 4\n",
    "np.random.permutation(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "In the space below create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this in one line of code by extracting the number of rows of `X_norm` using the `shape` attribute and then passing it to the  `np.random.permutation()` function. Remember the `shape` attribute returns a tuple with two numbers in the form `(rows,columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[507 131 179  53 587 578 538 223 823 413 167 492 691  59  62 454 384 954\n",
      " 925 520 136 899 817  87 631  94 541 182 392  50 281 641 980  67 202 124\n",
      " 273 137 317 449 750  12 688 749 559  23 821 944 114  82 966 731 497 639\n",
      " 423 710 203 653 729  92  80 163  73 975 728 512 965 938 459 562 430 219\n",
      "   4 669 144 192 693 628 829 910 341 579 522  84 873 857 368 707 118 274\n",
      " 860  10 161 415 877 796  75 329 918 170 551 548 793 212  68 896 850 314\n",
      " 815 783 740 818 753 259 671  70 184 558 696 606 898 111 323 903 473 627\n",
      " 882 657 701 381 584 992 272 249 978 348 735 169 215 484 500 859 862 556\n",
      " 889 849 570 623 574 600 428 319  43 420 252 481 134 603 802 702 804 355\n",
      " 364 396 232 769 405 345 555 152 258 645 468 499 947 614 915 282 228 834\n",
      " 766 411 941 539 554 398 897 376 906 328 846 655 366 588 514 435  64 343\n",
      " 711 615 344 610 964  20 904 380 988 383 260 685  77 981 912  79 557 374\n",
      " 401 646 666 460 972 461 806  57 989 285 812 445 902 811 838 886 123 361\n",
      " 759 234  18 526 575 836 287 832 246   8 150 835 483 866 216 486 434 708\n",
      " 166 477 957 967 826 801 191 403 649  35 294 385 858 196 608 436 346 275\n",
      " 128 352 761 442 532 362 887 917 268 589  31 236 970 204 393   0 455 764\n",
      " 193   3 612 424 339 197 848 386 412 198  11 333 418 391   1 113 712  47\n",
      "  14 387 581  72 713 842 390 493 159 264 998 188 295 837 549 148 642 508\n",
      " 824  97 227  44 963 101 491  32 138 143 267 872 379 663 534 659 692 433\n",
      " 279 139 516 951  13 325 647 312 913  81 880 937 583  89 221  93 503 703\n",
      "  17 633 501 315 300 298 125  78 733 638  86 813  27 747  42  96 456 597\n",
      " 791 280 340 224 879 784 958  45 505  51 864   6 854 895 755  15 814 292\n",
      " 207  16 776 331 956 371 654 658 931 760 738 521 439 469 616  46 629 790\n",
      " 270 119 624 621 919 429 467 546 326 991 997 843 140 448 613 800 321 395\n",
      " 865 782 488  61 388 905 568  69 154 335 190 940 852 261 723 195 727  38\n",
      "  41 762 885 241 301 462 304 389 939 756 803 839 297 709 510  85 773 465\n",
      " 157 604 644 378 625 336 506 416 235 893 266 248 888 598 736 206   7 205\n",
      " 466  37 732 744 881 145 774 171 535 928 142 932 444 595 127 878 675 673\n",
      " 528 450 582 316 617 739 175 269 515 721 431 350 427 787 369 330 591 822\n",
      " 102 112  54 126 276 400 594 874 797 409 704 667 565 408   5 414 785 290\n",
      " 943 863 410 271 165 209 115 318 106 320 440 181 177 172 949 365 656 577\n",
      " 953 494 250 698 763 674 985 567 472 183 513 458 662 254 132 724 283 961\n",
      " 531 767 299 519 478 847 441 525 226 844 751 244 632 700 716 668 697 892\n",
      " 637 370  34 831 788 596 302  66 257 349 825 730 153  76  95 479 200 164\n",
      " 544 529 914 909 930 775 511 670  30 543 946 187 679 908 986 994 313  22\n",
      " 185 995 502 952 969 217 719 533  28 242 158 962 107 225 237 569 717 571\n",
      " 798 960 347 971  60  39 277 251  88 630 737 524 640 471 661 920 509 699\n",
      "  83 452 851  29 351 496 523 680 550 942 404 916 687 861 504 820 682 933\n",
      " 605 683 208 363 229 210 291 518 770 265 810 935 725 353 309 421 146 845\n",
      " 757 109  74 765 714 974 868 840 213 677 222 168 230 576 417 160 734 360\n",
      " 399 474 303 566 545 342 402 284 482 572 394 996  63 322 635 619 780 422\n",
      " 463  98 924 786  25 948 105 592 334 929 495  99 626 178  58 934 475 359\n",
      " 247 875 563 239 108 453 664 104 781 620 841 149 950 743 959 110 199  56\n",
      " 999 255 358 718 636 517 922 926 133 979 715 306 634 779 437 485 890 100\n",
      " 900 547 726 819 867 327 141 660 977 833 884 816 233 650 694 984 129 976\n",
      " 406 580  40 720 130 180 286 103 553  33 527 536 676 337 311 162 457 871\n",
      " 987 542 156 447 201 705 373 564 155 367 231 487 973 805 332 540 278  36\n",
      " 573  26 968 289 552 690 706 611 590 307 789 665 262 263 602 794 894 982\n",
      " 407 561 451 121 173 147  21 419 308 741 498 356 855 609 256 921 305 560\n",
      " 354 678  19 211 772 643 438 911 748 186 537 372 758   2 808 771 681 752\n",
      "   9 651 927 426 777 828 288 189 480 238 809 936 686 923 853 530 253 807\n",
      " 754 993 607 243 122 955 593 489 742  55 983 296 443 240 883 876 778 722\n",
      "  91 768 425 599 470 338 827  49 856 799 357 464 377 117 293 220 382  65\n",
      " 310 446 585 990 689 432 945 792 194 214 218 375 746 174 684 830 490 601\n",
      " 324 648 672 891 245  52 907 652 176 869 695 795 151 622  48 586 901 397\n",
      "  24 870 135 618  71 120 116 476  90 745]\n"
     ]
    }
   ],
   "source": [
    "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
    "row_indices = np.random.permutation(X_norm.shape[0])\n",
    "print(row_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create the three datasets using the `row_indices` ndarray to select the rows that will go into each dataset. Rememeber that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. Each set requires just one line of code to create. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make any necessary calculations.\n",
    "# You can save your calculations into variables to use later.\n",
    "row_indices_size = row_indices.size\n",
    "row_indices_prc60 = int(row_indices_size*0.6)\n",
    "# Create a Training Set\n",
    "X_train = X_norm[:row_indices_prc60]\n",
    "\n",
    "# Create a Cross Validation Set\n",
    "X_crossVal = X_norm[int(row_indices_size*0.6):int(row_indices_prc60 + row_indices_size*0.2)]\n",
    "# Create a Test Set\n",
    "X_test = X_norm[int(row_indices_prc60 + row_indices_size*0.2):int(row_indices_size)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you performed the above calculations correctly, then `X_tain` should have 600 rows and 20 columns, `X_crossVal` should have 200 rows and 20 columns, and `X_test` should have 200 rows and 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 20)\n",
      "(200, 20)\n",
      "(200, 20)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of X_train\n",
    "print(X_train.shape)\n",
    "\n",
    "# Print the shape of X_crossVal\n",
    "print(X_crossVal.shape)\n",
    "\n",
    "# Print the shape of X_test\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
